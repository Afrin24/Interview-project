{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "df=pd.read_csv('C:/Users/Dell/Desktop/Interview.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import feature_selection\n",
    "from sklearn import tree\n",
    "from sklearn import utils\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import feature_selection\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1234 entries, 0 to 1233\n",
      "Data columns (total 28 columns):\n",
      "Date of Interview                                                                                     1233 non-null object\n",
      "Client name                                                                                           1234 non-null object\n",
      "Industry                                                                                              1233 non-null object\n",
      "Location                                                                                              1233 non-null object\n",
      "Position to be closed                                                                                 1233 non-null object\n",
      "Nature of Skillset                                                                                    1233 non-null object\n",
      "Interview Type                                                                                        1233 non-null object\n",
      "Name(Cand ID)                                                                                         1233 non-null object\n",
      "Gender                                                                                                1233 non-null object\n",
      "Candidate Current Location                                                                            1233 non-null object\n",
      "Candidate Job Location                                                                                1233 non-null object\n",
      "Interview Venue                                                                                       1233 non-null object\n",
      "Candidate Native location                                                                             1233 non-null object\n",
      "Have you obtained the necessary permission to start at the required time                              1029 non-null object\n",
      "Hope there will be no unscheduled meetings                                                            986 non-null object\n",
      "Can I Call you three hours before the interview and follow up on your attendance for the interview    986 non-null object\n",
      "Can I have an alternative number/ desk number. I assure you that I will not trouble you too much      986 non-null object\n",
      "Have you taken a printout of your updated resume. Have you read the JD and understood the same        985 non-null object\n",
      "Are you clear with the venue details and the landmark.                                                985 non-null object\n",
      "Has the call letter been shared                                                                       988 non-null object\n",
      "Expected Attendance                                                                                   1228 non-null object\n",
      "Observed Attendance                                                                                   1233 non-null object\n",
      "Marital Status                                                                                        1233 non-null object\n",
      "Unnamed: 23                                                                                           0 non-null float64\n",
      "Unnamed: 24                                                                                           0 non-null float64\n",
      "Unnamed: 25                                                                                           0 non-null float64\n",
      "Unnamed: 26                                                                                           0 non-null float64\n",
      "Unnamed: 27                                                                                           0 non-null float64\n",
      "dtypes: float64(5), object(23)\n",
      "memory usage: 270.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "#### Looking into the data set , we can say that we have 1234 records with 28 columns/features\n",
    "#### Firstly, we can clearly eleminate the last 5 columns , which have only null values\n",
    "#### Secondly, we need to shorten and modify the column in order to make the data more interpretable\n",
    "#### We need to clean the data before modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Unnamed: 23\",'Unnamed: 24','Unnamed: 25','Unnamed: 26','Unnamed: 27'],axis=1,inplace=True)\n",
    "df.columns=['date','client','industry','location','closedpos','skills','type','id','gender','currloc','jobloc','venue','natloc','permit','meeting','call','no.','resume','clear','letter','expat','obsat','marit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the string format to date format \n",
    "#### Extracting year, month, day and day of week from the date column and appending the columns to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.index[df[\"date\"].isnull()],axis=0,inplace=True)\n",
    "df.date=df.date.str.replace(\" \",\"\")\n",
    "df.date=df.date.str.replace(r'&\\d[\\d].\\d\\d\\w\\w','')\n",
    "df.date=df.date.str.replace(r'&\\d.\\d\\d\\w\\w','')\n",
    "df.date=df.date.str.replace('/','.')\n",
    "df.date=df.date.str.replace('-Apr-','.04.')\n",
    "df.date=df.date.str.replace('â€“Apr-','.04.')\n",
    "df.date=df.date.str.replace('Apr','.04.')\n",
    "df.date=df.date.str.replace(r'\\W16','.2016')\n",
    "df.date=df.date.str.replace(r'\\W15','.2015')\n",
    "df.date=df.date.str.replace('-','.')\n",
    "from datetime import datetime\n",
    "df['date']=pd.to_datetime(df['date'],format='%d.%m.%Y')\n",
    "df[\"date\"]=df[\"date\"].dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame({\"year\":[],\"month\":[],\"day\":[]})\n",
    "df=pd.concat([df,df2],sort=False)\n",
    "df2=pd.DataFrame({\"dayofyear\":[]})\n",
    "df=pd.concat([df,df2],sort=False)\n",
    "df2=pd.DataFrame({\"dayofweek\":[]})\n",
    "df=pd.concat([df,df2],sort=False)\n",
    "for i,s in df.iterrows():\n",
    "    k=df[\"date\"][i].timetuple()\n",
    "    df[\"year\"][i]=k.tm_year\n",
    "    df[\"month\"][i]=k.tm_mon\n",
    "    df[\"day\"][i]=k.tm_mday\n",
    "    df[\"dayofweek\"][i]=datetime.isoweekday(df[\"date\"][i])\n",
    "    df.dayofyear[i]=k.tm_yday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observed attendance column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.obsat.replace({'No':'N','Yes':'Y','yes':'Y','no':'N','yes ':'Y','No ':'N','NO':'N','no ':'N'},inplace=True)\n",
    "from sklearn import preprocessing\n",
    "le=preprocessing.LabelEncoder()\n",
    "df.loc[:,'obsat']=le.fit_transform(df.loc[:,'obsat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.month.unique():\n",
    "    print(i,(df[(df['month']==i) & (df.obsat==1)].shape[0]),(df[(df['month']==i) & (df.obsat==0)].shape[0]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.dayofweek.unique():\n",
    "    print(i,(df[(df['dayofweek']==i) & (df.obsat==1)].shape[0]),(df[(df['dayofweek']==i) & (df.obsat==0)].shape[0]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.year.unique():\n",
    "    print (i)\n",
    "    print(df[(df['year']==i) & (df.obsat==1)].shape[0])\n",
    "    print(df[(df['year']==i) & (df.obsat==0)].shape[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# native location column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"natloc\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['natloc'].replace({'Delhi /NCR':'Delhi','- Cochin- ':'Cochin'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['natloc'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['client'].replace({'Hospira':'H','Aon Hewitt':'A','UST':'U','Standard Chartered Bank':'S','ANZ':'A1','Pfizer':'P','Standard Chartered Bank Chennai':'S','Aon hewitt Gurgaon':'A','Astrazeneca':'As','Flextronics':'F','Prodapt':'P1','Williams Lea':'W','Barclays':'B','Hewitt':'A','Woori Bank':'Wb'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meeting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[\"meeting\"].unique():\n",
    "            print(i,(df[(df['meeting']==i) & (df.obsat==1)].shape[0]),(df[(df['meeting']==i) & (df.obsat==0)].shape[0]),sep=\" \")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.meeting.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.meeting.replace({'Yes':'Y','Na':'N','No':'N','yes':'Y','Not sure':'N','Not Sure':'N','cant Say':'N'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.index[df.meeting.isnull()],axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[\"meeting\"].unique():\n",
    "            print(i,(df[(df['meeting']==i) & (df.obsat==1)].shape[0]),(df[(df['meeting']==i) & (df.obsat==0)].shape[0]),sep=\" \")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['industry'].replace({'Pharmaceuticals':'P','IT Services':'I','IT Products and Services':'I','Electronics':'E','Telecom':'E','IT':'I','BFSI':'B'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[\"permit\"].unique():\n",
    "            print(i,(df[(df['permit']==i) & (df.obsat==1)].shape[0]),(df[(df['permit']==i) & (df.obsat==0)].shape[0]),sep=\" \")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.index[df.permit.isnull()],axis=0,inplace=True)\n",
    "df.permit.replace({'Yes':'Y','No':'N','Not yet':'N','Yet to confirm':'N','yes':'Y','Na':'N'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[\"permit\"].unique():\n",
    "            print(i,(df[(df['permit']==i) & (df.obsat==1)].shape[0]),(df[(df['permit']==i) & (df.obsat==0)].shape[0]),sep=\" \")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[\"resume\"].unique():\n",
    "            print(i,(df[(df['resume']==i) & (df.obsat==1)].shape[0]),(df[(df['resume']==i) & (df.obsat==0)].shape[0]),sep=\" \")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.resume.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['resume'].replace({'Yes':'Y', 'No':'N', 'No- will take it soon':'N', 'Not yet':'N', 'yes':'Y', 'Na':'N',\n",
    "       'Not Yet':'N'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.index[df.resume.isnull()],axis=0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[\"resume\"].unique():\n",
    "            print(i,(df[(df['resume']==i) & (df.obsat==1)].shape[0]),(df[(df['resume']==i) & (df.obsat==0)].shape[0]),sep=\" \")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[\"expat\"].unique():\n",
    "            print(i,(df[(df['expat']==i) & (df.obsat==1)].shape[0]),(df[(df['expat']==i) & (df.obsat==0)].shape[0]),sep=\" \")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['expat'].replace({'Yes':'Y','No':'N','yes':'Y','11:00 AM':'Y','10.30 Am':'Y'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,series in df.iterrows():\n",
    "        if((series.expat=='Uncertain') & (series.obsat==1)):\n",
    "            df.loc[i,'expat']='Y'\n",
    "        elif ((series.expat=='Uncertain') &( series.obsat==0)):\n",
    "            df.loc[i,'expat']='N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[\"expat\"].unique():\n",
    "            print(i,(df[(df['expat']==i) & (df.obsat==1)].shape[0]),(df[(df['expat']==i) & (df.obsat==0)].shape[0]),sep=\" \")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[\"letter\"].unique():\n",
    "            print(i,(df[(df['letter']==i) & (df.obsat==1)].shape[0]),(df[(df['letter']==i) & (df.obsat==0)].shape[0]),sep=\" \")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['letter'].replace({'Yes':'Y', 'Havent Checked':'Y', 'No':'N', 'Need To Check':'N', 'Not sure':'Y','Not Sure':'N', 'Not yet':'N', 'no':'N', 'yes':'Y', 'Na':'N'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[\"letter\"].unique():\n",
    "            print(i,(df[(df['letter']==i) & (df.obsat==1)].shape[0]),(df[(df['letter']==i) & (df.obsat==0)].shape[0]),sep=\" \")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[\"clear\"].unique():\n",
    "            print(i,(df[(df['clear']==i) & (df.obsat==1)].shape[0]),(df[(df['clear']==i) & (df.obsat==0)].shape[0]),sep=\" \")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clear'].replace({'Yes':'Y', 'No':'N', 'No- I need to check':'N', 'yes':'Y', 'Na':'N', 'no':'N'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[\"clear\"].unique():\n",
    "            print(i,(df[(df['clear']==i) & (df.obsat==1)].shape[0]),(df[(df['clear']==i) & (df.obsat==0)].shape[0]),sep=\" \")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[\"no.\"].unique():\n",
    "            print(i,(df[(df['no.']==i) & (df.obsat==1)].shape[0]),(df[(df['no.']==i) & (df.obsat==0)].shape[0]),sep=\" \")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no.'].replace({'Yes':'Y', 'No':'N', 'No I have only thi number':'N', 'yes':'Y', 'Na':'N'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[\"no.\"].unique():\n",
    "            print(i,(df[(df['no.']==i) & (df.obsat==1)].shape[0]),(df[(df['no.']==i) & (df.obsat==0)].shape[0]),sep=\" \")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[\"call\"].unique():\n",
    "            print(i,(df[(df['call']==i) & (df.obsat==1)].shape[0]),(df[(df['call']==i) & (df.obsat==0)].shape[0]),sep=\" \")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['call'].replace({'Yes':'Y', 'No':'N', 'No Dont':'Y', 'yes':'Y', 'Na':'N'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[\"call\"].unique():\n",
    "            print(i,(df[(df['call']==i) & (df.obsat==1)].shape[0]),(df[(df['call']==i) & (df.obsat==0)].shape[0]),sep=\" \")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Currloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.currloc.replace({'Chennai':'C','Gurgaon':'G','Bangalore':'B','Hyderabad':'H','Delhi':'D','chennai':'C','- Cochin- ':'K','Noida':'N','CHENNAI':'C','chennai ':'C'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.venue.replace({'Hosur':'H', 'Gurgaon':'G', 'Bangalore':'B', 'Chennai':'C', 'Hyderabad':'H',\n",
    "       '- Cochin- ':'K', 'Noida':'N'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jobloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.jobloc.replace({'Hosur':'H', 'Bangalore':'B', 'Chennai':\"C\", 'Gurgaon':'G', 'Visakapatinam':'V',\n",
    "       '- Cochin- ':'K', 'Noida':'N'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].replace({'Scheduled Walkin':'SW', 'Scheduled ':'S', 'Walkin':'W', 'Scheduled Walk In':'SW',\n",
    "       'Walkin ':'W'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.location.replace({'Chennai':'C', 'Gurgaon':'G', 'Bangalore':'B', 'Hyderabad':'H', 'Gurgaonr':'G',\n",
    "       'Delhi':'D', 'chennai':'C', '- Cochin- ':'K', 'Noida':'N', 'CHENNAI':'C', 'chennai ':'C'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closedpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.closedpos.replace({'Production- Sterile':'P','Selenium testing':'S','Dot Net':'D','AML':'A','Trade Finance':'T','Routine':'R','Niche':'N'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping the id column as this is similar to the serial number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"id\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label encoding all columns except date,skills and obseved attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.drop([\"date\",\"skills\",\"obsat\"],axis=1):\n",
    "    df.loc[:,i]=le.fit_transform(df.loc[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Seeing the feature importance using random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop([\"skills\",\"date\",\"obsat\"],axis=1)\n",
    "y=df[\"obsat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_importance(X,y):\n",
    "    rf=ensemble.RandomForestClassifier()\n",
    "    rf.fit(X,y)\n",
    "    return pd.DataFrame(rf.feature_importances_,columns=[\"Importance\"],index=X.columns).sort_values(\"Importance\",ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to plot graph to see how Precision varies with no of features using DECISION TREE (RFECV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelstats1(X,y):\n",
    "    np.random.seed(42)\n",
    "    Xtrain,Xtest,ytrain,ytest=train_test_split(X,y,test_size=.25,random_state=42)\n",
    "    stats=[]\n",
    "    modelnames=[\"LR\",\"DecisionTree\",\"KNN\",\"NB\"]\n",
    "    models=list()\n",
    "    models.append(linear_model.LogisticRegression(C=10))\n",
    "    models.append(tree.DecisionTreeClassifier())\n",
    "    models.append(neighbors.KNeighborsClassifier())\n",
    "    models.append(naive_bayes.GaussianNB())\n",
    "    for name,model in zip(modelnames,models):\n",
    "        if name==\"KNN\":\n",
    "            k=[l for l in range(5,17,2)]\n",
    "            grid={\"n_neighbors\":k}\n",
    "            grid_obj = GridSearchCV(estimator=model,param_grid=grid,scoring=\"f1\")\n",
    "            grid_fit =grid_obj.fit(Xtrain,ytrain)\n",
    "            model = grid_fit.best_estimator_\n",
    "            model.fit(Xtrain,ytrain)\n",
    "            name=name+\"(\"+str(grid_fit.best_params_[\"n_neighbors\"])+\")\"\n",
    "            print(grid_fit.best_params_)\n",
    "        else:\n",
    "            model.fit(Xtrain,ytrain)\n",
    "        trainprediction=model.predict(Xtrain)\n",
    "        testpredicti\n",
    "        (metrics.recall_score(ytrain,trainprediction))\n",
    "        scores.append(metrics.roc_auc_score(ytrain,trainprediction))\n",
    "        stats.append(scores)\n",
    "        scores=list()\n",
    "        scores.append(name+\"-test\")\n",
    "        scores.append(metrics.accuracy_score(ytest,testprediction))\n",
    "        scores.append(metrics.precision_score(ytest,testprediction))\n",
    "        scores.append(metrics.recall_score(ytest,testprediction))\n",
    "        scores.append(metrics.roc_auc_score(ytest,testprediction))\n",
    "        stats.append(scores)\n",
    "    \n",
    "    colnames=[\"MODELNAME\",\"ACCURACY\",\"PRECISION\",\"RECALL\",\"AUC\"]\n",
    "    return pd.DataFrame(stats,columns=colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to plot graph to see how Precision varies with no. of features using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp=get_importance(X,y)\n",
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_selection(X,y):\n",
    "    np.random.seed(42)\n",
    "    rf=ensemble.RandomForestClassifier()\n",
    "    train=[]\n",
    "    test=[]\n",
    "    loss=[]\n",
    "    m=[rf]\n",
    "    s=[\"Random Forest\"]\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.25,random_state=42)\n",
    "    for j in range(0,len(m)):\n",
    "        #print(s[j])\n",
    "        model=m[j]\n",
    "        for i in range(1,30):\n",
    "            rfecv=feature_selection.RFE(estimator=model,n_features_to_select=i)\n",
    "            rfecv.fit(X_train,y_train)\n",
    "            cols=X.columns[rfecv.get_support()]\n",
    "            X_=X_train[cols]\n",
    "            X_t=X_test[cols]\n",
    "            rfecv.fit(X_,y_train)\n",
    "            \n",
    "            #model.fit(X_,y)\n",
    "            #print(cols)\n",
    "            train.append(metrics.precision_score(y_train,rfecv.predict(X_)))\n",
    "            test.append(metrics.precision_score(y_test,rfecv.predict(X_t)))\n",
    "            loss.append(metrics.log_loss(y_test,rfecv.predict_proba(X_t)))\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(1,30,1),train)\n",
    "    plt.plot(np.arange(1,30,1),test)\n",
    "    plt.title(\"Optimal Number of Features (Random Forest) \")\n",
    "    plt.legend(['train score', 'test score'], loc='upper left')\n",
    "    plt.ylim(.7,.8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to plot graph to see how Precision varies with no of features using DECISION TREE (RFECV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_selection\n",
    "def get_feat_dt(X,y):\n",
    "    np.random.seed(42)\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.25,random_state=42)\n",
    "    model=tree.DecisionTreeClassifier()\n",
    "    n=X.shape[1]\n",
    "    tr_score=[]\n",
    "    ts_score=[]\n",
    "    for i in range(1,n):\n",
    "        rfecv=feature_selection.RFE(model,n_features_to_select=i)\n",
    "        rfecv.fit(X_train,y_train)\n",
    "        col=X.columns[rfecv.get_support()]\n",
    "        model.fit(X_train[col],y_train)\n",
    "        tr_p=model.predict(X_train[col])\n",
    "        ts_p=model.predict(X_test[col])\n",
    "        tr_score.append(metrics.precision_score(y_train,tr_p))\n",
    "        ts_score.append(metrics.precision_score(y_test,ts_p))\n",
    "    plt.figure()\n",
    "    plt.plot(range(1,n),tr_score)\n",
    "    plt.plot(range(1,n),ts_score)\n",
    "    plt.xlabel(\"min_features using Decison Tree\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.legend(['train score', 'test score'], loc='upper left')\n",
    "    plt.ylim(.7,.8)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate the scores of different ML models on the label encoded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelstats1(X,y):\n",
    "    np.random.seed(42)\n",
    "    Xtrain,Xtest,ytrain,ytest=train_test_split(X,y,test_size=.25,random_state=42)\n",
    "    stats=[]\n",
    "    modelnames=[\"LR\",\"DecisionTree\",\"KNN\",\"NB\"]\n",
    "    models=list()\n",
    "    models.append(linear_model.LogisticRegression(C=10))\n",
    "    models.append(tree.DecisionTreeClassifier())\n",
    "    models.append(neighbors.KNeighborsClassifier())\n",
    "    models.append(naive_bayes.GaussianNB())\n",
    "    for name,model in zip(modelnames,models):\n",
    "        if name==\"KNN\":\n",
    "            k=[l for l in range(5,17,2)]\n",
    "            grid={\"n_neighbors\":k}\n",
    "            grid_obj = GridSearchCV(estimator=model,param_grid=grid,scoring=\"f1\")\n",
    "            grid_fit =grid_obj.fit(Xtrain,ytrain)\n",
    "            model = grid_fit.best_estimator_\n",
    "            model.fit(Xtrain,ytrain)\n",
    "            name=name+\"(\"+str(grid_fit.best_params_[\"n_neighbors\"])+\")\"\n",
    "            print(grid_fit.best_params_)\n",
    "        else:\n",
    "            model.fit(Xtrain,ytrain)\n",
    "        trainprediction=model.predict(Xtrain)\n",
    "        testprediction=model.predict(Xtest)\n",
    "        scores=list()\n",
    "        scores.append(name+\"-train\")\n",
    "        scores.append(metrics.accuracy_score(ytrain,trainprediction))\n",
    "        scores.append(metrics.precision_score(ytrain,trainprediction))\n",
    "        scores.append(metrics.recall_score(ytrain,trainprediction))\n",
    "        scores.append(metrics.roc_auc_score(ytrain,trainprediction))\n",
    "        stats.append(scores)\n",
    "        scores=list()\n",
    "        scores.append(name+\"-test\")\n",
    "        scores.append(metrics.accuracy_score(ytest,testprediction))\n",
    "        scores.append(metrics.precision_score(ytest,testprediction))\n",
    "        scores.append(metrics.recall_score(ytest,testprediction))\n",
    "        scores.append(metrics.roc_auc_score(ytest,testprediction))\n",
    "        stats.append(scores)\n",
    "    \n",
    "    colnames=[\"MODELNAME\",\"ACCURACY\",\"PRECISION\",\"RECALL\",\"AUC\"]\n",
    "    return pd.DataFrame(stats,columns=colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate the score for the RandomForestClassifier models with different number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rf(X,y,i):\n",
    "    np.random.seed(42)\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.25,random_state=42)\n",
    "    model=ensemble.RandomForestClassifier()\n",
    "    rfecv=feature_selection.RFE(model,n_features_to_select=i)\n",
    "    rfecv.fit(X_train,y_train)\n",
    "    col=X.columns[rfecv.get_support()]\n",
    "    model.fit(X_train[col],y_train)\n",
    "    tr_p=model.predict(X_train[col])\n",
    "    ts_p=model.predict(X_test[col])\n",
    "    print (col)\n",
    "    print(i)\n",
    "    print(\"Train Set\")\n",
    "    print(\"precison\",metrics.precision_score(y_train,tr_p)*100)\n",
    "    print(\"recall\",metrics.recall_score(y_train,tr_p)*100)\n",
    "    print(\"accuracy\",metrics.accuracy_score(y_train,tr_p)*100)\n",
    "    print(\"log loss\",metrics.log_loss(y_train,model.predict_proba(X_train[col])))\n",
    "    print(\"Test Set\")\n",
    "    print(\"precision\",metrics.precision_score(y_test,ts_p)*100)\n",
    "    print(\"recall\",metrics.recall_score(y_test,ts_p)*100)\n",
    "    print(\"acuuracy\",metrics.accuracy_score(y_test,ts_p)*100)\n",
    "    print(\"log loss\",metrics.log_loss(y_test,model.predict_proba(X_test[col])))\n",
    "    \n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    fpr, tpr, thresholds = roc_curve(ts_p, y_test)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    name=\"RF\"\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange',  label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy',  linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    st='Receiver operating characteristic '+name\n",
    "    plt.title(st)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Function to calculate the score for the RandomForestClassifier models with different number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dt(X,y,i):\n",
    "    np.random.seed(42)\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.25,random_state=42)\n",
    "    model=tree.DecisionTreeClassifier()\n",
    "    rfecv=feature_selection.RFE(model,n_features_to_select=i)\n",
    "    rfecv.fit(X_train,y_train)\n",
    "    col=X.columns[rfecv.get_support()]\n",
    "    model.fit(X_train[col],y_train)\n",
    "    tr_p=model.predict(X_train[col])\n",
    "    ts_p=model.predict(X_test[col])\n",
    "    print(i)\n",
    "    print(\"Train Set\")\n",
    "    print(\"precison\",metrics.precision_score(y_train,tr_p)*100)\n",
    "    print(\"recall\",metrics.recall_score(y_train,tr_p)*100)\n",
    "    print(\"accuracy\",metrics.accuracy_score(y_train,tr_p)*100)\n",
    "    print(\"log loss\",metrics.log_loss(y_train,model.predict_proba(X_train[col])))\n",
    "    print(\"Test Set\")\n",
    "    print(\"precision\",metrics.precision_score(y_test,ts_p)*100)\n",
    "    print(\"recall\",metrics.recall_score(y_test,ts_p)*100)\n",
    "    print(\"acuuracy\",metrics.accuracy_score(y_test,ts_p)*100)\n",
    "    print(\"log loss\",metrics.log_loss(y_test,model.predict_proba(X_test[col])))\n",
    "    \n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    fpr, tpr, thresholds = roc_curve(ts_p, y_test)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    name=\"DT\"\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange',  label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy',  linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    st='Receiver operating characteristic '+name\n",
    "    plt.title(st)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph of optimal no. of features in DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feat_dt(df.drop([\"date\",\"obsat\",\"skills\"],axis=1),df.obsat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph of optimal no of features using RFE selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_selection(df.drop([\"date\",\"skills\",\"obsat\"],axis=1),df.obsat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running modelstats1 on all features of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelstats1(df.drop([\"date\",\"obsat\",\"skills\"],axis=1),df.obsat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running RandomForestClassifier on 8 features of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_rf(df.drop([\"date\",\"obsat\",\"skills\"],axis=1),df.obsat,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running RandomForestClassifier on 9 features of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_rf(df.drop([\"date\",\"obsat\",\"skills\"],axis=1),df.obsat,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(, ytest)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange',  label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy',  linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "st='Receiver operating characteristic '+name\n",
    "plt.title(st)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
